# ant build properties.

# the bigdata base directory
bigdata.dir=../..

# Where to find the pre-build bigdata classes.
bigdata.build.dir=${bigdata.dir}/ant-build

bigdata.install.lib.dir=${bigdata.dir}/

# TODO This is ignored. Parameterize the test to use the specified data file.
#rdf.data.dir=${bigdata.dir}/bigdata-rdf/src/resources/data/foaf

# TODO Parameterize the test to use the specified parallelism/strategy.
nparallel=8

##
# javac options
##

# debug=on|off
javac.debug=off
# debuglevel=lines,vars,source (or any combination thereof).
javac.debuglevel=lines,vars,source
javac.verbose=off
#javac.target=1.6
#javac.source=1.6
javac.encoding=Cp1252

# GAS properties.
#
# Note: By default, the files will wind up in ./ant-build/bin
#
# Note: By degault, the server jvm will optimize for throughput and can have
# high variation in throughput due to long GC pauses for larger heaps. You can
# use the CMS-I GC mode to minimize latency at the expense of some throughput.

# The port at which the NanoSparqlServer will respond (if started).
nanoServerPort=80

# The maximum size of the java heap.
maxMem=4g

# The namespace of the KB instance (multiple KBs can be in the same database).
namespace=kb

# The name of the journal file to be used (ignored for memstore).
journalFile=bigdata.jnl

# The name of the file used to configure the Journal.
journalPropertyFile=RWStore.properties

# The name of the file used for the journal.
bufferMode=DiskRW
#bufferMode=MemStore

# files to load.
#load=-load xxx -load yyy
load=-load ${bigdata.dir}/bigdata-rdf/src/resources/data/foaf

# The #of threads to use for GATHER and SCATTER
nthreads=4

# The #of random starting vertices to select.
nsamples=1000

# The seed for the random number generator.
seed=217

# BFS, SSSP, etc.  Will run corresponding XXX class.
analytic=BFS

# The class used to schedule and compact the new frontier.
#scheduler=-schedulerClass com.bigdata.rdf.graph.impl.scheduler.STScheduler
scheduler=-schedulerClass com.bigdata.rdf.graph.impl.scheduler.CHMScheduler
#scheduler=-schedulerClass com.bigdata.rdf.graph.impl.scheduler.TLScheduler
#scheduler=-schedulerClass com.bigdata.rdf.graph.impl.scheduler.TLScheduler2

#
# Profiler parameters.
#

# No profiler.
profilerAgent=
# linux-64
#profilerAgent=-agentpath:/nas/install/yjp-10.0.1/bin/linux-x86-64/libyjpagent.so
profilerAgent=-agentpath:/nas/install/yjp-12.0.6/bin/linux-x86-64/libyjpagent.so
# Windows
#profilerAgent="-agentpath:C:/Program Files/YourKit Java Profiler 9.0.2/bin/win32/yjpagent.dll"
# Windows Server 2008
#profilerAgent="-agentpath:C:/Program Files (x86)/YourKit Java Profiler 9.0.4/bin/win64/yjpagent.dll"

# No profiler.
profilerAgentOptions=
# all profiling initially disabled.
#profilerAgentOptions=-agentlib:yjpagent=disableexceptiontelemetry,disablestacktelemetry

profiler=${profilerAgent} ${profilerAgentOptions}

# Configure GC.
gcopts=
#gcopts=-verbose:gc
#gcopts=-XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode
#gcopts=-XX:+UseParallelOldGC
#gcopts=-XX:+UnlockExperimentalVMOptions -XX:+UseG1GC

# Generates detailed logging on the JVM GC behavior.  The service will
# start in the configured service directory, so the log file will be in
# that directory as well.  The service directory is typically on local
# disk, so that is where you need to look for this file.
gcdebug=
#gcdebug=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:jvm_gc.log

# all jvm args for query.
jvmArgs=-server -Xmx${maxMem} -XX:MaxDirectMemorySize=2g -showversion ${gcopts} ${gcdebug} ${profiler} -Dlog4j.configuration=file:log4j.properties  -Dcom.bigdata.journal.AbstractJournal.file=${journalFile} 
# -Dlog4j.debug
